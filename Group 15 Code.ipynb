{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9990398",
   "metadata": {},
   "source": [
    "### Cosc2671 Assignment 2 Group 15 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9342a6e-f935-48e5-b497-01b2039bf843",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import praw\n",
    "import datetime as dt\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c516616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tools\n",
    "tokenizer = TweetTokenizer()\n",
    "tokenizer = TweetTokenizer(preserve_case=False)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74aa5ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    #Remove non-alphabetic characters but keep @, #, and apostrophe\n",
    "    text = re.sub(r'[^a-zA-Z@\\s#\\']', '', text)\n",
    "    # Tokenize\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    # Remove stopwords and short tokens; lemmatize\n",
    "    cleaned = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words and len(token) > 2]\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8680d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reddit API credentials\n",
    "clientid = \"FgY4iejqu83Q9QpgNMX9dQ\"\n",
    "clientsecret = \"eeSZYZUjfMIAQ5qcULOc9SSYOHghFQ\"\n",
    "password = \"1357900jkx\"\n",
    "username = \"Traditional-Shine402\"\n",
    "useragents = 'client for SNAM2024'\n",
    "reddit = praw.Reddit(client_id=clientid, client_secret=clientsecret,password=password,\n",
    "                           username=username,user_agent=useragents)\n",
    "\n",
    "\n",
    "# Keywords and Subreddits\n",
    "keywords = [\n",
    "    \"moon landing fake\", \n",
    "    \"moon landing hoax\", \n",
    "    \"fake moon landing\", \n",
    "    \"did we land on the moon\", \n",
    "    \"moon landing conspiracy\", \n",
    "    \"moon landing was staged\", \n",
    "    \"apollo mission fake\", \n",
    "    \"moon landing faked\", \n",
    "    \"moon hoax\", \n",
    "    \"apollo hoax\", \n",
    "    \"moon conspiracy\", \n",
    "    \"moon landing lies\", \n",
    "    \"nasa faked moon landing\"]\n",
    "\n",
    "subreddits = [\"conspiracy\", \"moonlandingfake\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95f426e5-73b2-42c7-98d7-2a0b75552293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 2849 posts.\n",
      "Fetched 25047 comments.\n"
     ]
    }
   ],
   "source": [
    "#Data collection\n",
    "posts = []\n",
    "\n",
    "for subreddit in subreddits:\n",
    "    for keyword in keywords:\n",
    "        for submission in reddit.subreddit(subreddit).search(keyword, limit=10000):\n",
    "            posts.append({\n",
    "                'subreddit': subreddit,\n",
    "                'title': submission.title.lower(),\n",
    "                'text': submission.selftext.lower(),\n",
    "                'author': str(submission.author),\n",
    "                'score': submission.score,\n",
    "                'created_utc': dt.datetime.fromtimestamp(submission.created_utc),\n",
    "                'id': submission.id,\n",
    "                'num_comments': submission.num_comments\n",
    "            })\n",
    "\n",
    "posts_df = pd.DataFrame(posts)\n",
    "posts_df['cleaned_tokens'] = posts_df['text'].astype(str).apply(preprocess_text)\n",
    "posts_df.to_csv(\"reddit_posts.csv\", index=False)\n",
    "print(f\"Fetched {len(posts_df)} posts.\")\n",
    "\n",
    "# Fetch comments\n",
    "comments_data = []\n",
    "\n",
    "for post_id in posts_df['id']:\n",
    "    if len(comments_data) > 25000:\n",
    "        break\n",
    "    submission = reddit.submission(id=post_id)\n",
    "    submission.comments.replace_more(limit=0)\n",
    "    for comment in submission.comments.list():\n",
    "        comments_data.append({\n",
    "            'post_id': post_id,\n",
    "            'comment_body': comment.body.lower(),\n",
    "            'author': str(comment.author),\n",
    "            'score': comment.score,\n",
    "            'created_utc': dt.datetime.fromtimestamp(comment.created_utc)\n",
    "        })\n",
    "\n",
    "comments_df = pd.DataFrame(comments_data)\n",
    "comments_df['cleaned_tokens'] = comments_df['comment_body'].astype(str).apply(preprocess_text)\n",
    "comments_df.to_csv(\"reddit_comments.csv\", index=False)\n",
    "print(f\"Fetched {len(comments_df)} comments.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cbe480e-d910-41d0-8011-ac276a4df588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>cleaned_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>conspiracy</td>\n",
       "      <td>did we ever land on the moonâ€¦?</td>\n",
       "      <td></td>\n",
       "      <td>Own_Teacher3433</td>\n",
       "      <td>738</td>\n",
       "      <td>2024-08-23 22:28:45</td>\n",
       "      <td>1ezbh2v</td>\n",
       "      <td>759</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>conspiracy</td>\n",
       "      <td>can you tell me why you think the moon landing...</td>\n",
       "      <td>i come in peace! i am a about to start my phd ...</td>\n",
       "      <td>Ms_Photon</td>\n",
       "      <td>863</td>\n",
       "      <td>2023-03-12 01:48:43</td>\n",
       "      <td>11olzpd</td>\n",
       "      <td>1374</td>\n",
       "      <td>[come, peace, start, phd, astronomy, first, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>conspiracy</td>\n",
       "      <td>if the moon landing was fake, why the enemies ...</td>\n",
       "      <td></td>\n",
       "      <td>TimmyOTule</td>\n",
       "      <td>196</td>\n",
       "      <td>2024-09-27 22:26:50</td>\n",
       "      <td>1fqmhry</td>\n",
       "      <td>527</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>conspiracy</td>\n",
       "      <td>why do people get so defensive when the 1969 m...</td>\n",
       "      <td>whenever a moon landing conspiracy is posted t...</td>\n",
       "      <td>Majin_Vegeta_</td>\n",
       "      <td>249</td>\n",
       "      <td>2024-01-03 10:27:29</td>\n",
       "      <td>18x3uai</td>\n",
       "      <td>449</td>\n",
       "      <td>[whenever, moon, landing, conspiracy, posted, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>conspiracy</td>\n",
       "      <td>if the moon landing was faked how have other c...</td>\n",
       "      <td>in my limited understanding of space travel, w...</td>\n",
       "      <td>5afari</td>\n",
       "      <td>383</td>\n",
       "      <td>2022-07-13 22:57:31</td>\n",
       "      <td>vy2lws</td>\n",
       "      <td>525</td>\n",
       "      <td>[limited, understanding, space, travel, would,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2844</th>\n",
       "      <td>moonlandingfake</td>\n",
       "      <td>why i no longer believe the apollo moon landin...</td>\n",
       "      <td></td>\n",
       "      <td>HelicopterJesus</td>\n",
       "      <td>3</td>\n",
       "      <td>2021-10-27 04:31:21</td>\n",
       "      <td>qgbkci</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2845</th>\n",
       "      <td>moonlandingfake</td>\n",
       "      <td>here's the truth</td>\n",
       "      <td>moon landings were faked on the moon.ðŸ’€</td>\n",
       "      <td>Sea-Mark-7504</td>\n",
       "      <td>11</td>\n",
       "      <td>2023-03-04 04:55:36</td>\n",
       "      <td>11h8s9e</td>\n",
       "      <td>5</td>\n",
       "      <td>[moon, landing, faked, moon]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2846</th>\n",
       "      <td>moonlandingfake</td>\n",
       "      <td>bruh</td>\n",
       "      <td>i've gotten 50 new types of brain cancer from ...</td>\n",
       "      <td>YesterdayDirect8401</td>\n",
       "      <td>20</td>\n",
       "      <td>2022-11-26 00:36:44</td>\n",
       "      <td>z4dkp6</td>\n",
       "      <td>6</td>\n",
       "      <td>[gotten, new, type, brain, cancer, came, schoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2847</th>\n",
       "      <td>moonlandingfake</td>\n",
       "      <td>is it me or has the internet become the most e...</td>\n",
       "      <td>i used to use it to win all kinds of arguments...</td>\n",
       "      <td>ElectronicPresenc</td>\n",
       "      <td>12</td>\n",
       "      <td>2022-09-21 16:45:45</td>\n",
       "      <td>xjxct3</td>\n",
       "      <td>7</td>\n",
       "      <td>[used, use, win, kind, argument, would, sound,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2848</th>\n",
       "      <td>moonlandingfake</td>\n",
       "      <td>the proof</td>\n",
       "      <td>i wanted to ask, if i provide help to recreate...</td>\n",
       "      <td>Mradul_Sharma</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-07-14 17:55:04</td>\n",
       "      <td>vyqdi1</td>\n",
       "      <td>3</td>\n",
       "      <td>[wanted, ask, provide, help, recreate, moon, l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2849 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            subreddit                                              title  \\\n",
       "0          conspiracy                     did we ever land on the moonâ€¦?   \n",
       "1          conspiracy  can you tell me why you think the moon landing...   \n",
       "2          conspiracy  if the moon landing was fake, why the enemies ...   \n",
       "3          conspiracy  why do people get so defensive when the 1969 m...   \n",
       "4          conspiracy  if the moon landing was faked how have other c...   \n",
       "...               ...                                                ...   \n",
       "2844  moonlandingfake  why i no longer believe the apollo moon landin...   \n",
       "2845  moonlandingfake                                   here's the truth   \n",
       "2846  moonlandingfake                                               bruh   \n",
       "2847  moonlandingfake  is it me or has the internet become the most e...   \n",
       "2848  moonlandingfake                                          the proof   \n",
       "\n",
       "                                                   text               author  \\\n",
       "0                                                            Own_Teacher3433   \n",
       "1     i come in peace! i am a about to start my phd ...            Ms_Photon   \n",
       "2                                                                 TimmyOTule   \n",
       "3     whenever a moon landing conspiracy is posted t...        Majin_Vegeta_   \n",
       "4     in my limited understanding of space travel, w...               5afari   \n",
       "...                                                 ...                  ...   \n",
       "2844                                                         HelicopterJesus   \n",
       "2845             moon landings were faked on the moon.ðŸ’€        Sea-Mark-7504   \n",
       "2846  i've gotten 50 new types of brain cancer from ...  YesterdayDirect8401   \n",
       "2847  i used to use it to win all kinds of arguments...    ElectronicPresenc   \n",
       "2848  i wanted to ask, if i provide help to recreate...        Mradul_Sharma   \n",
       "\n",
       "      score         created_utc       id  num_comments  \\\n",
       "0       738 2024-08-23 22:28:45  1ezbh2v           759   \n",
       "1       863 2023-03-12 01:48:43  11olzpd          1374   \n",
       "2       196 2024-09-27 22:26:50  1fqmhry           527   \n",
       "3       249 2024-01-03 10:27:29  18x3uai           449   \n",
       "4       383 2022-07-13 22:57:31   vy2lws           525   \n",
       "...     ...                 ...      ...           ...   \n",
       "2844      3 2021-10-27 04:31:21   qgbkci             1   \n",
       "2845     11 2023-03-04 04:55:36  11h8s9e             5   \n",
       "2846     20 2022-11-26 00:36:44   z4dkp6             6   \n",
       "2847     12 2022-09-21 16:45:45   xjxct3             7   \n",
       "2848      3 2022-07-14 17:55:04   vyqdi1             3   \n",
       "\n",
       "                                         cleaned_tokens  \n",
       "0                                                    []  \n",
       "1     [come, peace, start, phd, astronomy, first, th...  \n",
       "2                                                    []  \n",
       "3     [whenever, moon, landing, conspiracy, posted, ...  \n",
       "4     [limited, understanding, space, travel, would,...  \n",
       "...                                                 ...  \n",
       "2844                                                 []  \n",
       "2845                       [moon, landing, faked, moon]  \n",
       "2846  [gotten, new, type, brain, cancer, came, schoo...  \n",
       "2847  [used, use, win, kind, argument, would, sound,...  \n",
       "2848  [wanted, ask, provide, help, recreate, moon, l...  \n",
       "\n",
       "[2849 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67697dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment_body</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>cleaned_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1ezbh2v</td>\n",
       "      <td>###[meta] sticky comment\\n\\n[rule 2](https://w...</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-08-23 22:28:47</td>\n",
       "      <td>[###meta, sticky, comment, rule, apply, replyi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ezbh2v</td>\n",
       "      <td>i once asked a.i how to get sugar out of a gas...</td>\n",
       "      <td>dinahmoon</td>\n",
       "      <td>799</td>\n",
       "      <td>2024-08-24 01:15:41</td>\n",
       "      <td>[asked, get, sugar, gas, tank, told, use, stra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1ezbh2v</td>\n",
       "      <td>everyone loves ai when it gives you the answer...</td>\n",
       "      <td>Binarydemons</td>\n",
       "      <td>156</td>\n",
       "      <td>2024-08-24 03:49:59</td>\n",
       "      <td>[everyone, love, give, answer, want, hear]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1ezbh2v</td>\n",
       "      <td>wow that ai has such an unbiased sounding name</td>\n",
       "      <td>before686entenz</td>\n",
       "      <td>642</td>\n",
       "      <td>2024-08-23 23:18:37</td>\n",
       "      <td>[wow, unbiased, sounding, name]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1ezbh2v</td>\n",
       "      <td>i don't know, but china confirmed their probes...</td>\n",
       "      <td>AccordingWarning9534</td>\n",
       "      <td>322</td>\n",
       "      <td>2024-08-24 01:16:11</td>\n",
       "      <td>[know, china, confirmed, probe, moon, rover, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25042</th>\n",
       "      <td>6hvagj</td>\n",
       "      <td>science olympiad in tenth grade, why?</td>\n",
       "      <td>regular_poster</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-18 22:08:12</td>\n",
       "      <td>[science, olympiad, tenth, grade]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25043</th>\n",
       "      <td>6hvagj</td>\n",
       "      <td>i'm an lpn, lol.</td>\n",
       "      <td>regular_poster</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-06-18 10:19:56</td>\n",
       "      <td>[lpn, lol]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25044</th>\n",
       "      <td>6hvagj</td>\n",
       "      <td>&gt;a bird doesn't escape gravity.\\n\\nneither doe...</td>\n",
       "      <td>EnoughNoLibsSpam</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-18 10:53:16</td>\n",
       "      <td>[bird, escape, gravity, neither, astronaut]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25045</th>\n",
       "      <td>6hvagj</td>\n",
       "      <td>as i said, theres a reason question 1 is quest...</td>\n",
       "      <td>EnoughNoLibsSpam</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-18 09:55:54</td>\n",
       "      <td>[said, there, reason, question, question, imme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25046</th>\n",
       "      <td>6hvagj</td>\n",
       "      <td>so we agree that the gravity of earth will in-...</td>\n",
       "      <td>EnoughNoLibsSpam</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-22 03:39:50</td>\n",
       "      <td>[agree, gravity, earth, infact, affect, rocket...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25047 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       post_id                                       comment_body  \\\n",
       "0      1ezbh2v  ###[meta] sticky comment\\n\\n[rule 2](https://w...   \n",
       "1      1ezbh2v  i once asked a.i how to get sugar out of a gas...   \n",
       "2      1ezbh2v  everyone loves ai when it gives you the answer...   \n",
       "3      1ezbh2v     wow that ai has such an unbiased sounding name   \n",
       "4      1ezbh2v  i don't know, but china confirmed their probes...   \n",
       "...        ...                                                ...   \n",
       "25042   6hvagj              science olympiad in tenth grade, why?   \n",
       "25043   6hvagj                                   i'm an lpn, lol.   \n",
       "25044   6hvagj  >a bird doesn't escape gravity.\\n\\nneither doe...   \n",
       "25045   6hvagj  as i said, theres a reason question 1 is quest...   \n",
       "25046   6hvagj  so we agree that the gravity of earth will in-...   \n",
       "\n",
       "                     author  score         created_utc  \\\n",
       "0             AutoModerator      1 2024-08-23 22:28:47   \n",
       "1                 dinahmoon    799 2024-08-24 01:15:41   \n",
       "2              Binarydemons    156 2024-08-24 03:49:59   \n",
       "3           before686entenz    642 2024-08-23 23:18:37   \n",
       "4      AccordingWarning9534    322 2024-08-24 01:16:11   \n",
       "...                     ...    ...                 ...   \n",
       "25042        regular_poster      1 2017-06-18 22:08:12   \n",
       "25043        regular_poster      2 2017-06-18 10:19:56   \n",
       "25044      EnoughNoLibsSpam      1 2017-06-18 10:53:16   \n",
       "25045      EnoughNoLibsSpam      1 2017-06-18 09:55:54   \n",
       "25046      EnoughNoLibsSpam      1 2017-06-22 03:39:50   \n",
       "\n",
       "                                          cleaned_tokens  \n",
       "0      [###meta, sticky, comment, rule, apply, replyi...  \n",
       "1      [asked, get, sugar, gas, tank, told, use, stra...  \n",
       "2             [everyone, love, give, answer, want, hear]  \n",
       "3                        [wow, unbiased, sounding, name]  \n",
       "4      [know, china, confirmed, probe, moon, rover, s...  \n",
       "...                                                  ...  \n",
       "25042                  [science, olympiad, tenth, grade]  \n",
       "25043                                         [lpn, lol]  \n",
       "25044        [bird, escape, gravity, neither, astronaut]  \n",
       "25045  [said, there, reason, question, question, imme...  \n",
       "25046  [agree, gravity, earth, infact, affect, rocket...  \n",
       "\n",
       "[25047 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
