{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9990398",
   "metadata": {},
   "source": [
    "### Cosc2671 Assignment 2 Group 15 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8680d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import praw\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20918d17",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
},
 {
   "cell_type": "code",
   "execution_count": null,
   "id": "2175daa9-b228-47a1-84fc-3a42f08aa3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import nltk\n",
    "import string\n",
    "import tweepy\n",
    "import time\n",
    "import prawcore\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from community import community_louvain\n",
    "from pyvis.network import Network\n",
    "from collections import Counter\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3569b135-3ed0-488e-a5fe-19cad51efd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def redditClient():\n",
    "    try:\n",
    "        clientid = \"FgY4iejqu83Q9QpgNMX9dQ\"\n",
    "        clientsecret = \"eeSZYZUjfMIAQ5qcULOc9SSYOHghFQ\"\n",
    "        password = \"1357900jkx\"\n",
    "        username = \"Traditional-Shine402\"\n",
    "        useragents = 'client for SNAM2024'\n",
    "        redditClient = praw.Reddit(client_id=clientid, client_secret=clientsecret,password=password,\n",
    "                                   username=username,user_agent=useragents)\n",
    "    except KeyError:\n",
    "        sys.stderr.write('Key or secret token are invalid.\\n')\n",
    "        sys.exit(1)\n",
    "    return redditClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01362ee4-18c8-48b3-bd21-efb9e8f032c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processText(text, tokenizer, stemmer, stopwords):\n",
    "    text = text.lower()\n",
    "    lTokens = tokenizer.tokenize(text)\n",
    "    lTokens = [token.strip() for token in lTokens]\n",
    "    lStemmedTokens = set([stemmer.stem(tok) for tok in lTokens])\n",
    "    return [tok for tok in lStemmedTokens if tok not in stopwords and not tok.isdigit()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9480a886-8059-4700-b2bf-aa53287068a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments=[]\n",
    "comments_id=[]\n",
    "comments_time=[]\n",
    "start_2024 = datetime(2024, 1, 1)\n",
    "end_2024 = datetime(2025, 1, 1)\n",
    "start = int(start_2024.timestamp())\n",
    "end = int(end_2024.timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808f240d-68c8-4b1a-8c38-0441f1322768",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "hotlimit=50000\n",
    "postTokeniser = nltk.tokenize.TweetTokenizer()\n",
    "lPunct = list(string.punctuation)\n",
    "lStopwords = nltk.corpus.stopwords.words('english') + lPunct + ['rt', 'via', '...', '…', '\"', \"'\", '`','’']\n",
    "postStemmer = nltk.stem.PorterStemmer()\n",
    "lPosts = []\n",
    "timestamp=[]\n",
    "client=redditClient()\n",
    "Subreddit=['Moonlandingfake','conspiracy']\n",
    "keyword=['moon', 'landing', 'fake', 'Apollo', 'hoax', 'NASA', 'lie',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce72fa8-0b9f-4471-b03e-1d4b980eda1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub in Subreddit:\n",
    "    if len(lPosts) >= 5000:\n",
    "        break\n",
    "    subreddit=client.subreddit(sub)\n",
    "    for word in keyword:\n",
    "        try:\n",
    "            if len(lPosts) >= 5000:\n",
    "                break\n",
    "            for submission in subreddit.search(word,limit=1000):\n",
    "                if (start <= submission.created_utc < end):\n",
    "                    if len(lPosts) >= 5000:\n",
    "                        break\n",
    "                    if submission.selftext.strip():\n",
    "                        utc_timestamp = submission.created_utc\n",
    "                        timestamp.append(int(utc_timestamp))\n",
    "                        post_time = datetime.fromtimestamp(utc_timestamp)\n",
    "                        submissionTitle = submission.title\n",
    "                        lTokens = processText(text=submissionTitle, tokenizer=postTokeniser, stemmer=postStemmer, stopwords=lStopwords)\n",
    "                        lPosts.append(' '.join(lTokens))\n",
    "                        texts.append(submission.title + ' ' + submission.selftext)\n",
    "        except prawcore.exceptions.TooManyRequests:\n",
    "            time.sleep(60)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8bde30-7fce-4440-a150-517857bd6ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub in Subreddit:\n",
    "    if len(comments) >= 25000:\n",
    "        break\n",
    "    subreddit=client.subreddit(sub)\n",
    "    for word in keyword:\n",
    "        try:        \n",
    "            if len(comments) > 25000:\n",
    "                break\n",
    "            for submission in subreddit.search(word,limit=1000):\n",
    "                if (start <= submission.created_utc < end):\n",
    "                    submission.comments.replace_more(limit=None)\n",
    "                    for comment in submission.comments.list():\n",
    "                        if len(comments) >= 25000:\n",
    "                            break\n",
    "                        comments.append(comment.body)\n",
    "                        comments_id.append(comment.id)\n",
    "                        comments_time.append(comment.created_utc)\n",
    "        except prawcore.exceptions.TooManyRequests:\n",
    "            time.sleep(60)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9758e3-7243-4f86-a230-313025b7056e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016b7290-2544-4bc5-b021-6d1b37675fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV = pd.DataFrame({\n",
    "    'timestamp': timestamp,\n",
    "    'title': lPosts,\n",
    "    'full_text': texts,\n",
    "})\n",
    "CSV.to_csv('reddit_posts.csv',index=False,encoding='utf-8')\n",
    "CSV = pd.DataFrame({\n",
    "    'comments': comments,\n",
    "    'comments_id':comments_id,\n",
    "    'comments_time':comments_time\n",
    "})\n",
    "CSV.to_csv('reddit_comments.csv',index=False,encoding='utf-8')\n"
   ]
  }
